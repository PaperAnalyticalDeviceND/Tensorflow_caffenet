{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CaffeNet for PADs\n",
    "CaffeNet for PADs implemented in Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the following line to allow us to embed plots in Jupyter notebooks\n",
    "%matplotlib notebook\n",
    "\n",
    "# Load libraries. We need tensorflow and numpy for training the CNN,\n",
    "# matplotlib for plotting, os.path and PIL for loading images,\n",
    "# and random to partition the data into test and training sets\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from os.path import dirname, abspath\n",
    "from os.path import join\n",
    "import os.path\n",
    "import PIL\n",
    "import random\n",
    "import urllib.request\n",
    "from PIL import Image, ImageEnhance, ImageStat\n",
    "\n",
    "#seed random for putting images into training and test arrays\n",
    "random.seed(13456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lookup, output 0-8\n",
    "lookup = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "#variables\n",
    "classes = 9 #Amoxicillin rerun,Acetaminophen,Ciprofloxacin,Ceftriaxone,Metformin,Ampicillin,Azithromycin,Cefuroxime Axetil,Levofloxacin\n",
    "\n",
    "#Flags to create train and test variables first time through\n",
    "firstTrain = True\n",
    "firstTest = True\n",
    "\n",
    "#load training images\n",
    "with open('images/train/label.csv') as f:\n",
    "    #get lines\n",
    "    train_labels = f.readlines()\n",
    "    \n",
    "    #loop over label lines\n",
    "    for labels in train_labels:\n",
    "        #get filename/label\n",
    "        label_lookup, file = labels.split(',')\n",
    "        \n",
    "        #lookup\n",
    "        label = lookup[int(label_lookup)]\n",
    "        #print(\"Lookup training\", label_lookup, label)\n",
    "\n",
    "        #Load png file using the PIL library\n",
    "        im = PIL.Image.open('images/'+file.strip())\n",
    "\n",
    "        #add flattened image to train\n",
    "        if firstTrain:\n",
    "            #first time just set the train array to equal the first image\n",
    "            #also reset the flag to false\n",
    "            firstTrain = False\n",
    "\n",
    "            #save the image as a (1, 154587) vector. Images are 224x224 pixels\n",
    "            train = np.mat(np.asarray(im).flatten())\n",
    "            #add a \"1 hot\" vector to the label array\n",
    "            trainLabel = np.mat(np.eye(classes)[int(label)])\n",
    "        else:\n",
    "            #append once we have saved the first image               \n",
    "            train = np.append(train, np.mat(np.asarray(im).flatten()), axis=0)\n",
    "            #add a \"1 hot\" vector to the label array\n",
    "            trainLabel = np.append(trainLabel, np.mat(np.eye(classes)[int(label)]), axis=0)\n",
    "\n",
    "#load testing images\n",
    "with open('images/test/label.csv') as f:\n",
    "    #get lines\n",
    "    test_labels = f.readlines()\n",
    "    \n",
    "    #loop over label lines\n",
    "    for labels in test_labels:\n",
    "        #get filename/label\n",
    "        label_lookup, file = labels.split(',')\n",
    "        \n",
    "        #lookup\n",
    "        label = lookup[int(label_lookup)]\n",
    "        #print(\"Lookup test\", label_lookup, label)\n",
    "        \n",
    "        #Load png file using the PIL library\n",
    "        im = PIL.Image.open('images/'+file.strip())\n",
    "\n",
    "        #add flattened image to train\n",
    "        if firstTest:\n",
    "            #first time just set the test array to equal the first image\n",
    "            #also reset the flag to false\n",
    "            firstTest = False\n",
    "\n",
    "            #save the image as a (1, 154587) vector. Images are 224x224 pixels\n",
    "            test = np.mat(np.asarray(im).flatten())\n",
    "            #add a \"1 hot\" vector to the label array\n",
    "            testLabel = np.mat(np.eye(classes)[int(label)])\n",
    "        else:\n",
    "            #append once we have saved the first image               \n",
    "            test = np.append(test, np.mat(np.asarray(im).flatten()), axis=0)\n",
    "            #add a \"1 hot\" vector to the label array\n",
    "            testLabel = np.append(testLabel, np.mat(np.eye(classes)[int(label)]), axis=0)\n",
    "\n",
    "print(\"Train size\",train.shape, trainLabel.shape)\n",
    "print(\"Test size\",test.shape, testLabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for training\n",
    "#learning rate is the step size that we move in the opposite direction of the gradient for each weight/bias\n",
    "learning_rate = 1e-4 \n",
    "#an epoch represents having trained with a number of images equal to the training test size\n",
    "max_epochs = 100\n",
    "display_step_size = 10 # Number of iterations before checking on the performance of network (validation)\n",
    "#the prob_keep parameter represents the dropout, probability to keep units. This makes the network more robust\n",
    "prob_keep = 0.5\n",
    "\n",
    "#max pooling values\n",
    "mx_pooling_size = 2        #max pooling size 2 *2\n",
    "mx_pooling_window = 3      #max pooling window 3 *3\n",
    "\n",
    "# Convolutional Layer 1.\n",
    "filter_size1 = 11          # Convolution filters are 11 x 11 pixels.\n",
    "num_filters1 = 96\n",
    "filter_stride1 = 4\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters2 = 256\n",
    "\n",
    "# Convolutional Layer 3.\n",
    "filter_size3 = 3          # Convolution filters are 3 x 3 pixels.\n",
    "num_filters3 = 384\n",
    "\n",
    "# Convolutional Layer 4.\n",
    "filter_size4 = 3          # Convolution filters are 3 x 3 pixels.\n",
    "num_filters4 = 384\n",
    "\n",
    "# Convolutional Layer 5.\n",
    "filter_size5 = 3          # Convolution filters are 3 x 3 pixels.\n",
    "num_filters5 = 256\n",
    "\n",
    "# Fully-connected layers.\n",
    "fc_neurons1 = 4096         # Number of neurons in fully-connected layer.\n",
    "fc_neurons2 = 4096         # Number of neurons in second fully-connected layer.\n",
    "\n",
    "\n",
    "#Image properties\n",
    "img_shape = (227, 227)\n",
    "\n",
    "#the images are color so 3 channels\n",
    "channels = 3\n",
    "\n",
    "#location of the weights/biases and architecture for the CNN checkpoint\n",
    "model_checkpoint = \"tf_ckpt/caffenet_pad_1.ckpt\"\n",
    "\n",
    "#image batch size\n",
    "image_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN\n",
    "#create place holders, these will be loaded with data as we train\n",
    "X = tf.placeholder(tf.float32, shape=[None, img_shape[0]*img_shape[1]*channels], name='X') #the set of input images\n",
    "X_image = tf.reshape(X, [-1, img_shape[0], img_shape[1], channels]) #a single image\n",
    "Y = tf.placeholder(tf.float32, shape=[None, classes], name='Y')     #the label set\n",
    "Y_classes = tf.argmax(Y, axis=1)                               #the classes(subjects)\n",
    "\n",
    "#dropout (keep probability)\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "#initial weight values\n",
    "def generate_weights(shape, name):\n",
    "    # Create new matrix\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=5e-2), name=name)\n",
    "\n",
    "#initial bias values\n",
    "def generate_biases(size, name):\n",
    "    #create biases\n",
    "    return tf.Variable(tf.constant(0.0, shape=[size]), name=name)\n",
    "\n",
    "# compute convolutions with relu output\n",
    "def convolution(input_data,num_channels, filter_size, num_filters, stride, name_w, name_b): \n",
    "    #shape for weights\n",
    "    shape = [filter_size, filter_size, num_channels, num_filters]\n",
    "    # Generate new weights\n",
    "    W = generate_weights(shape=shape, name=name_w)\n",
    "    # generate new biases, one for each filter.\n",
    "    b= generate_biases(size=num_filters, name=name_b)\n",
    "    #tensorflow convolution\n",
    "    out = tf.nn.conv2d(input=input_data, filter=W, strides=[1, stride, stride, 1], padding='SAME')\n",
    "    # Add the biases\n",
    "    out= tf.nn.bias_add(out,b)\n",
    "    #relu activation\n",
    "    out = tf.nn.relu(out)\n",
    "    return out, W, b\n",
    "\n",
    "#max pooling layer\n",
    "def max_pooling(input_data,size,window): \n",
    "    out = tf.nn.max_pool(value=input_data, ksize=[1, window, window, 1], strides=[1, size, size, 1], padding='SAME')\n",
    "    return out\n",
    "\n",
    "def reduce(tensor):\n",
    "    #reduce the 4-dim tensor, the output from the\n",
    "    #conv/maxpooling to 2-dim as input to the fully-connected layer\n",
    "    features = tensor.get_shape()[1:4].num_elements() # The volume\n",
    "    reduced = tf.reshape(tensor, [-1, features])\n",
    "    return reduced, features\n",
    "\n",
    "#compute the fully connected layer\n",
    "def compute_fc_layer(input_data,input_size, output_size, name_w, name_b, use_relu=True, user_dropout=False):\n",
    "    # generate new weights and biases.\n",
    "    W = generate_weights(shape=[input_size, output_size], name=name_w)\n",
    "    b = generate_biases(size=output_size, name=name_b)\n",
    "    #compute the out\n",
    "    out = tf.matmul(input_data, W) + b\n",
    "    # Use ReLU?\n",
    "    if use_relu:\n",
    "        out = tf.nn.relu(out)\n",
    "    #Add dropout regularisation if its not the out layer\n",
    "    if user_dropout:\n",
    "         out = tf.nn.dropout(out, keep_prob)\n",
    "    return out, W, b\n",
    "\n",
    "#CNN architecture\n",
    "#layer 1\n",
    "conv_layer1, conv_W1, conv_B1 = convolution(input_data=X_image,num_channels=channels,\n",
    "                                   filter_size=filter_size1,num_filters=num_filters1, stride=filter_stride1, name_w='conv_W1', name_b='conv_B1')\n",
    "\n",
    "#layer 1 has max pooling\n",
    "max_pooling_layer_1 = max_pooling(input_data=conv_layer1,size=mx_pooling_size,window=mx_pooling_window)\n",
    "\n",
    "#need to normalize here\n",
    "#norm1 = tf.nn.lrn(max_pooling_layer_1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n",
    "\n",
    "#Layer 2\n",
    "conv_layer2, conv_W2, conv_B2 =convolution(input_data=max_pooling_layer_1,num_channels=num_filters1,\n",
    "                                  filter_size=filter_size2,num_filters=num_filters2, stride=1, name_w='conv_W2', name_b='conv_B2')\n",
    "\n",
    "#layer 2 has max pooling\n",
    "max_pooling_layer_2 = max_pooling(input_data=conv_layer2,size=mx_pooling_size,window=mx_pooling_window)\n",
    "\n",
    "#need to normalize here\n",
    "#norm2 = tf.nn.lrn(max_pooling_layer_2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm2')\n",
    "\n",
    "#Layer 3\n",
    "conv_layer3, conv_W3, conv_B3 =convolution(input_data=max_pooling_layer_2,num_channels=num_filters2,\n",
    "                                  filter_size=filter_size3,num_filters=num_filters3, stride=1, name_w='conv_W3', name_b='conv_B3')\n",
    "\n",
    "#Layer 4\n",
    "conv_layer4, conv_W4, conv_B4 =convolution(input_data=conv_layer3,num_channels=num_filters3,\n",
    "                                  filter_size=filter_size4,num_filters=num_filters4, stride=1, name_w='conv_W4', name_b='conv_B4')\n",
    "\n",
    "#Layer 5\n",
    "conv_layer5, conv_W5, conv_B5 =convolution(input_data=conv_layer4,num_channels=num_filters4,\n",
    "                                  filter_size=filter_size5,num_filters=num_filters5, stride=1, name_w='conv_W5', name_b='conv_B5')\n",
    "\n",
    "#layer 2 has max pooling\n",
    "max_pooling_layer_5 = max_pooling(input_data=conv_layer5,size=mx_pooling_size,window=mx_pooling_window)\n",
    "\n",
    "#reshape the out from covolution layers for input into fully connected layers\n",
    "Xi, features = reduce(max_pooling_layer_5)\n",
    "\n",
    "#Fully connected layers\n",
    "FC1, fc_W1, fc_B1 = compute_fc_layer(input_data=Xi,input_size=features,\n",
    "                       output_size=fc_neurons1, name_w='fc_W1', name_b='fc_B1', use_relu=True,user_dropout=True)\n",
    "\n",
    "FC2, fc_W2, fc_B2 = compute_fc_layer(input_data=FC1,input_size=fc_neurons1,\n",
    "                       output_size=fc_neurons2, name_w='fc_W2', name_b='fc_B2', use_relu=True, user_dropout=True)\n",
    "\n",
    "FC3, fc_W3, fc_B3 = compute_fc_layer(input_data=FC2,input_size=fc_neurons2,\n",
    "                       output_size=classes, name_w='fc_W3', name_b='fc_B3', use_relu=False, user_dropout=False)\n",
    "\n",
    "output = tf.nn.softmax(FC3, name='output') #softmax output\n",
    "pred = tf.argmax(output, axis=1, name='pred') # predictions\n",
    "#compute cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=FC3, labels=tf.stop_gradient(Y)))\n",
    "#optimise the cost function\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "#Compute Accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(pred, Y_classes), tf.float32))\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver([conv_W1,conv_B1,conv_W2,conv_B2,conv_W3,conv_B3,conv_W4,conv_B4,conv_W5,conv_B5,fc_W1,fc_B1,fc_W2,fc_B2,fc_W3,fc_B3]) #tf.global_variables ())\n",
    "#saver = tf.train.Saver(tf.global_variables ())\n",
    "\n",
    "print(max_pooling_layer_5.shape, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow session\n",
    "init = tf.global_variables_initializer() #initialize\n",
    "\n",
    "# Tensorflow session variables\n",
    "training_loss = []  # training loss\n",
    "test_loss =[[],[]]  #Keep test loses at every epoch\n",
    "training_accuracy =[0] #Keep training accuracy\n",
    "test_accurracy = [0]  # accuracy on test data\n",
    "\n",
    "#run session\n",
    "with tf.Session() as sess:\n",
    "    #initialize session\n",
    "    sess.run(init)\n",
    "    \n",
    "    #load in the saved weights, if the file exists\n",
    "    #checkpointing creates a number of files including .meta\n",
    "    if os.path.exists(model_checkpoint + \".meta\"):\n",
    "        saver.restore(sess, model_checkpoint)\n",
    "        print(\"Loaded saved checkpoint\",model_checkpoint)\n",
    "        \n",
    "    #start at epoch 0\n",
    "    epoch =0\n",
    "\n",
    "    #loop through the epochs we set (100)\n",
    "    while epoch < max_epochs+1:\n",
    "        #get a mini batch of size batchsize, \n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        loop_number = 0\n",
    "        \n",
    "        #lets take a smaller number for GPU, 250?\n",
    "        image_loops = math.floor(train.shape[0] / image_batch_size)\n",
    "        for i in range(image_loops):\n",
    "            #update loop number\n",
    "            loop_number = loop_number + 1\n",
    "\n",
    "            #get batch\n",
    "            training_data = {X: train[i*image_batch_size:(i+1)*image_batch_size], Y:trainLabel[i*image_batch_size:(i+1)*image_batch_size], keep_prob: prob_keep }\n",
    "\n",
    "            ##################################################################################\n",
    "            # Run the optimser!                                                              #\n",
    "            # This is where the magic happens, the optimizer will calculate the gradient     #\n",
    "            # based on the images in the training set and will adjust the weights and biases #\n",
    "            # by moving them in the opposite direction to the gradient by a distance equal    #\n",
    "            # to the learning rate.                                                          #\n",
    "            ##################################################################################\n",
    "            _, train_loss_batch,train_acc_batch = sess.run([optimizer, cost, accuracy], feed_dict=training_data)\n",
    "            ##################################################################################\n",
    "\n",
    "            #let's accumulate the loss and accuracy\n",
    "            train_loss += train_loss_batch\n",
    "            train_acc += train_acc_batch\n",
    "        \n",
    "        #adjust stat accumulations\n",
    "        train_loss = train_loss / loop_number\n",
    "        train_acc = train_acc / loop_number\n",
    "        \n",
    "        #save the training loss for graph\n",
    "        training_loss.append(train_loss) \n",
    "        # Print status every 10 iterations.\n",
    "        if epoch % display_step_size == 0:\n",
    "            training_accuracy.append(train_acc * 100)\n",
    "            # After every 10 epochs, check the accuracy on the test data\n",
    "            #initialize stats\n",
    "            test_acc = 0\n",
    "            tst_loss = 0\n",
    "            loop_number = 0\n",
    "            \n",
    "            #actually lets take a smaller number for GPU, 250?\n",
    "            image_loops = math.floor(test.shape[0] / image_batch_size)\n",
    "            for i in range(image_loops):\n",
    "                #update loop number\n",
    "                loop_number = loop_number + 1\n",
    "\n",
    "                #get batch\n",
    "                test_data = {X: test[i*image_batch_size:(i+1)*image_batch_size], Y: testLabel[i*image_batch_size:(i+1)*image_batch_size], keep_prob: 1.}\n",
    "                test_acc_batch,tst_loss_batch = sess.run([accuracy,cost], feed_dict=test_data)\n",
    "\n",
    "                #let's accumulate the loss and accuracy\n",
    "                test_acc += test_acc_batch\n",
    "                tst_loss += tst_loss_batch\n",
    "                #print(\"Test loss\",tst_loss_batch)\n",
    "                    \n",
    "            #adjust stat accumulations\n",
    "            test_acc = test_acc / loop_number\n",
    "            tst_loss = tst_loss / loop_number\n",
    "                \n",
    "            #save the data for plotting\n",
    "            test_accurracy.append(test_acc*100)\n",
    "            test_loss[0].append(epoch)\n",
    "            test_loss[1].append(tst_loss)\n",
    "\n",
    "            print (\"Epoch: {0:>3}, Training Loss:{1:>6.8f}, Training Accuracy:{2:>6.1%}, Test loss: {3:>6.8f},\" \\\n",
    "                  \"Test accuracy: {4:>6.1%}\".format(epoch, train_loss, train_acc, tst_loss,test_acc))\n",
    "            \n",
    "            # Save the variables to disk.\n",
    "            save_path = saver.save(sess, model_checkpoint)\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "        epoch +=1 #next epoch\n",
    "\n",
    "    #and the graph\n",
    "    #tf.train.write_graph(sess.graph_def, \"tmp/load\", \"convnet_cifar10.pb\", True)\n",
    "\n",
    "    #print that training ended\n",
    "    print ('Optimisation done. Accuracy attained on test data:{0:.2f}'.format(max(test_accurracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots training loss\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=False, figsize=(10, 6))\n",
    "ax1.plot(training_loss, color='red', label='Training loss')\n",
    "ax1.plot(test_loss[0], test_loss[1],color ='blue',label='Test loss')\n",
    "ax1.set_title('Loss: Training vs Test')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.margins(.05)\n",
    "ax1.legend(loc='best')\n",
    "ax1.grid()\n",
    "\n",
    "# plot test accuracy\n",
    "ax2.plot(np.array(range(len(training_accuracy))) * display_step_size, training_accuracy,\n",
    "         color=\"red\", label='Training: Acc ={0:.1f}%'.format(np.max(training_accuracy)))\n",
    "ax2.plot(np.array(range(len(test_accurracy))) * display_step_size, test_accurracy,\n",
    "         color=\"blue\", label='Test: Acc = {0:.1f}%'.format(np.max(test_accurracy)))\n",
    "ax2.set_title('Accuracy: Training vs Test')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy %')\n",
    "ax2.axis([0, max_epochs + 5, 0, 105])\n",
    "ax2.legend(loc='best')\n",
    "ax2.grid()\n",
    "\n",
    "#show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "Let's use our trained network to predict which drug a picture belongs to.\n",
    "\n",
    "We will randomly load a picture and then show the prediction. You can try several examples by re-running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location of the weights/biases and architecture for the CNN (saved above)\n",
    "model_for_identification = model_checkpoint\n",
    "\n",
    "#called to identify subject in image\n",
    "def identify(image):\n",
    "    #reshape the image to an (1, 154587) vector\n",
    "    image = np.mat(np.asarray(image).flatten())\n",
    "    #create session\n",
    "    with tf.Session() as sess:\n",
    "        #load in the saved weights\n",
    "        saver.restore(sess, model_for_identification)\n",
    "        #find the prediction\n",
    "        result = sess.run(pred, feed_dict={X: image, keep_prob: 1.})\n",
    "        #we can look at the softmax output as well\n",
    "        prob_array = sess.run(output, feed_dict={X: image, keep_prob: 1.})\n",
    "        #print(\"op\",prob_array)\n",
    "        \n",
    "        #return result (add 1 as indexed from 1 not 0)\n",
    "        return result[0], prob_array\n",
    "\n",
    "\n",
    "#pick an image, subject 1 to 39 and image 1 to 10, let's throw randoms to choose\n",
    "test_drug = 8#random.randint(1,classes)\n",
    "test_image = 74#random.randint(1,100)\n",
    "\n",
    "#location of image.\n",
    "image_name = '1.37.png'\n",
    "\n",
    "#Load png file using the PIL library\n",
    "im = PIL.Image.open(join('images', str(test_drug) + '.' + str(test_image) + '.png'))\n",
    "\n",
    "#catagorize\n",
    "predicted_drug, predicted_prob = identify(im)\n",
    "\n",
    "#load drug names\n",
    "f = open('drug_names.txt')\n",
    "firstline = f.readline()\n",
    "drugs = firstline.split(',')\n",
    "#print(predicted_drug,drugs[predicted_drug], test_drug, test_image)\n",
    "\n",
    "#and print\n",
    "if predicted_drug == test_drug:\n",
    "    print(\"Drug\",drugs[test_drug], \"image\", test_image, \"\\033[1mCORRECTLY\\033[0m identified as drug\", drugs[predicted_drug])\n",
    "else:\n",
    "    print(\"Drug\",drugs[test_drug], \"image\", test_image, \"\\033[1mINCORRECTLY\\033[0m identified as drug\", drugs[predicted_drug])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get it\n",
    "urllib.request.urlretrieve( 'https://pad.crc.nd.edu/images/padimages/processed//Acetaminophen-12LanePADKenya2015-1-58861.processed.png', 'test.jpg')\n",
    "#Load png file using the PIL library\n",
    "img = PIL.Image.open('test.jpg')\n",
    "#crop out active area\n",
    "img = img.crop((71, 359, 71+636, 359+490))\n",
    "#lanes split\n",
    "lane = []\n",
    "\n",
    "#exclude these lanes\n",
    "exclude = \"AJ\"\n",
    "\n",
    "#loop over lanes\n",
    "for i in range(0,12):\n",
    "    if chr(65+i) not in exclude:\n",
    "        lane.append(img.crop((53*i, 0, 53*(i+1), 490)))\n",
    "\n",
    "#reconstruct\n",
    "imgout = Image.new(\"RGB\", (53 * len(lane), 490))\n",
    "\n",
    "#loop over lanes\n",
    "for i in range(0,len(lane)):\n",
    "    imgout.paste(lane[i], (53*i, 0, 53*(i+1), 490))\n",
    "\n",
    "#resize\n",
    "imgout = imgout.resize((227,227), Image.ANTIALIAS)\n",
    "\n",
    "#show it\n",
    "imgplot = plt.imshow(imgout)\n",
    "\n",
    "#catagorize\n",
    "predicted_drug, predicted_prob = identify(imgout)\n",
    "\n",
    "print(\"Drug predicted to be\", drugs[predicted_drug])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverse lookup, output 0-8\n",
    "r_lookup = [0, 1, 2, 3, 4, 6, 7, 8, 9]\n",
    "\n",
    "\n",
    "#location of the weights/biases and architecture for the CNN (saved above)\n",
    "model_for_identification = model_checkpoint\n",
    "\n",
    "#create session\n",
    "sess = tf.Session()\n",
    "\n",
    "#load in the saved weights\n",
    "saver.restore(sess, model_for_identification)\n",
    "\n",
    "#called to identify subject in image\n",
    "def identify(image):\n",
    "    #reshape the image to an (1, 154587) vector\n",
    "    image = np.mat(np.asarray(image).flatten())\n",
    "    #find the prediction\n",
    "    result = sess.run(pred, feed_dict={X: image, keep_prob: 1.})\n",
    "    #we can look at the softmax output as well\n",
    "    prob_array = sess.run(output, feed_dict={X: image, keep_prob: 1.})\n",
    "    #print(\"op\",prob_array)\n",
    "\n",
    "    #return result (add 1 as indexed from 1 not 0)\n",
    "    return result[0], prob_array\n",
    "\n",
    "#setting path for saved file\n",
    "path = \"msh_tanzania_data/catagorize/\"\n",
    "#setting directory\n",
    "dirs = os.listdir(path)\n",
    "\n",
    "#looping over all the pictures in catagorize folder\n",
    "for pics in dirs:\n",
    "    #try:\n",
    "    #open image to be categorized\n",
    "    im = PIL.Image.open(path + pics)\n",
    "    #identify image result\n",
    "    predicted_drug_rlookup, predicted_prob = identify(im)\n",
    "    \n",
    "    #lookup\n",
    "    predicted_drug = r_lookup[predicted_drug_rlookup]\n",
    "    \n",
    "    #load drug names\n",
    "    #g = open('msh_tanzania_data/drug_labels.csv')\n",
    "    #firstline = g.readline()\n",
    "    #drugs = firstline.split(',')\n",
    "    #print results to screen\n",
    "    #print(\"Image:\", image_name, \"identified as drug\", predicted_drug)# drugs[predicted_drug]\n",
    "    \n",
    "    write_to_file = join(str(predicted_drug) + \",\" + str(pics) + \"\\n\")\n",
    "\n",
    "    #print results to file.\n",
    "    labelfile = open(\"categorize_results_crs.txt\", \"a+\")\n",
    "    labelfile.write(write_to_file)\n",
    "    labelfile.close()\n",
    "\n",
    "    #except:\n",
    "    #print(\"Unable to write results to file for\", pics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location of the weights/biases and architecture for the CNN (saved above)\n",
    "model_for_identification = model_checkpoint\n",
    "classes = 9\n",
    "\n",
    "#called to identify subject in image\n",
    "def identify(image):\n",
    "    #reshape the image to an (1, 154587) vector\n",
    "    image = np.mat(np.asarray(image).flatten())\n",
    "    #create session\n",
    "    with tf.Session() as sess:\n",
    "        #load in the saved weights\n",
    "        saver = tf.train.import_meta_graph(model_for_identification+'.meta')\n",
    "        saver.restore(sess, model_for_identification) #tf.train.latest_checkpoint('tmp2/'))\n",
    "        \n",
    "        #get graph to extract tensors\n",
    "        graph = tf.get_default_graph()\n",
    "        pred = graph.get_tensor_by_name(\"pred:0\")\n",
    "        output = graph.get_tensor_by_name(\"output:0\")\n",
    "        X = graph.get_tensor_by_name(\"X:0\")\n",
    "        Placeholder = graph.get_tensor_by_name(\"Placeholder:0\")\n",
    "\n",
    "        #saver.restore(sess, model_for_identification)\n",
    "        \n",
    "        #find the prediction\n",
    "        result = sess.run(pred, feed_dict={X: image, Placeholder: 1.})\n",
    "        #we can look at the softmax output as well\n",
    "        prob_array = sess.run(output, feed_dict={X: image, Placeholder: 1.})\n",
    "        #print(\"op\",prob_array)\n",
    "        \n",
    "        #return result (add 1 as indexed from 1 not 0)\n",
    "        return result[0], prob_array\n",
    "\n",
    "#pick an image, subject 1 to 39 and image 1 to 10, let's throw randoms to choose\n",
    "test_drug = 8#random.randint(1,classes)\n",
    "test_image = 74#random.randint(1,100)\n",
    "\n",
    "#location of image.\n",
    "image_name = '1.37.png'\n",
    "\n",
    "#Load png file using the PIL library\n",
    "im = PIL.Image.open(join('images', str(test_drug) + '.' + str(test_image) + '.png'))\n",
    "\n",
    "#catagorize\n",
    "predicted_drug, predicted_prob = identify(im)\n",
    "\n",
    "#load drug names\n",
    "f = open('drug_names.txt')\n",
    "firstline = f.readline()\n",
    "drugs = firstline.split(',')\n",
    "#print(predicted_drug,drugs[predicted_drug], test_drug, test_image)\n",
    "\n",
    "#and print\n",
    "if predicted_drug == test_drug:\n",
    "    print(\"Drug\",drugs[test_drug], \"image\", test_image, \"\\033[1mCORRECTLY\\033[0m identified as drug\", drugs[predicted_drug])\n",
    "else:\n",
    "    print(\"Drug\",drugs[test_drug], \"image\", test_image, \"\\033[1mINCORRECTLY\\033[0m identified as drug\", drugs[predicted_drug])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
